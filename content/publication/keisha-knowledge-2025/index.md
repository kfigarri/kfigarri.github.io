---
title: 'Knowledge Collapse in LLMs: When Fluency Survives but Facts Fail under Recursive
  Synthetic Training'
authors:
- Figarri Keisha
- Zekun Wu
- Ze Wang
- Adriano Koshiyama
- Philip Treleaven
date: '2025-09-01'
publishDate: '2025-09-09T15:10:33.397308Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.2509.04796
abstract: Large language models increasingly rely on synthetic data due to human-written
  content scarcity, yet recursive training on model-generated outputs leads to model
  collapse, a degenerative process threatening factual reliability. We define knowledge
  collapse as a distinct three-stage phenomenon where factual accuracy deteriorates
  while surface fluency persists, creating \"confidently wrong\" outputs that pose
  critical risks in accuracy-dependent domains. Through controlled experiments with
  recursive synthetic training, we demonstrate that collapse trajectory and timing
  depend critically on instruction format, distinguishing instruction-following collapse
  from traditional model collapse through its conditional, prompt-dependent nature.
  We propose domain-specific synthetic training as a targeted mitigation strategy
  that achieves substantial improvements in collapse resistance while maintaining
  computational efficiency. Our evaluation framework combines model-centric indicators
  with task-centric metrics to detect distinct degradation phases, enabling reproducible
  assessment of epistemic deterioration across different language models. These findings
  provide both theoretical insights into collapse dynamics and practical guidance
  for sustainable AI training in knowledge-intensive applications where accuracy is
  paramount.
tags:
- Computer Science - Computation and Language
links:
- name: URL
  url: http://arxiv.org/abs/2509.04796
---
